{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from net import *\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from ssim_loss import *\n",
    "from metrics import *\n",
    "from DataConstructor import *\n",
    "from metrics import *\n",
    "from utils import show\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "MAE = 10240000\n",
    "MSE = 10240000\n",
    "SHANGHAITECH = \"B\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_load\n",
    "img_dir = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/train_data/images\"\n",
    "gt_dir = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/train_data/gt_map\"\n",
    "\n",
    "dataset = DatasetConstructor(img_dir, gt_dir, 400, 20)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzn/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# obtain the gpu device\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")\n",
    "\n",
    "# model construct\n",
    "net = SANet().to(cuda_device)\n",
    "\n",
    "# set optimizer and estimator\n",
    "criterion = SANetLoss(1).to(cuda_device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-5, weight_decay=5*1e-4)\n",
    "ae_batch = AEBatch().to(cuda_device)\n",
    "se_batch = SEBatch().to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(500):\n",
    "    dataset = dataset.train_model().shuffle()\n",
    "    # train\n",
    "    step = 0\n",
    "    for train_img_index, train_img, train_gt, data_ptc in train_loader:\n",
    "        # eval per 100 batch\n",
    "        if step % 100 == 0:\n",
    "            net.eval()\n",
    "            dataset = dataset.eval_model().shuffle()\n",
    "            loss_ = []\n",
    "            MAE_ = []\n",
    "            MSE_ = []\n",
    "            \n",
    "            rand_number = random.randint(0,19)\n",
    "            counter = 0\n",
    "            \n",
    "            for eval_img_index, eval_img, eval_gt, eval_data_ptc in eval_loader:\n",
    "                \n",
    "                # B\n",
    "                eval_x = eval_img.view(-1, 3, 768, 1024).cuda()\n",
    "                eval_y = eval_gt.view(-1, 1, 768, 1024).cuda()\n",
    "                # A\n",
    "#                     eval_x = eval_img.cuda()\n",
    "#                     eval_y = eval_gt.cuda()\n",
    "                eval_prediction = net(eval_x)\n",
    "                # That’s because numpy doesn’t support CUDA, \n",
    "                # so there’s no way to make it use GPU memory without a copy to CPU first. \n",
    "                # Remember that .numpy() doesn’t do any copy, \n",
    "                # but returns an array that uses the same memory as the tensor\n",
    "                eval_loss = criterion(eval_prediction, eval_y).data.cpu().numpy()\n",
    "                batch_ae = ae_batch(eval_prediction, eval_y).data.cpu().numpy()\n",
    "                batch_se = se_batch(eval_prediction, eval_y).data.cpu().numpy()\n",
    "                \n",
    "                # random show 1 sample\n",
    "                if rand_number == counter:\n",
    "                    origin_image = Image.open(\"/home/zzn/part_\" + SHANGHAITECH + \"_final/train_data/images/IMG_\" + str(eval_img_index.numpy()[0]) + \".jpg\")\n",
    "                    validate_pred_map = np.squeeze(eval_prediction.permute(0, 2, 3, 1).data.cpu().numpy())\n",
    "                    validate_gt_map = np.squeeze(eval_y.permute(0, 2, 3, 1).data.cpu().numpy())\n",
    "                    \n",
    "                    show(origin_image, validate_gt_map, validate_pred_map, eval_img_index.numpy()[0])\n",
    "                    gt_counts = np.sum(validate_gt_map)\n",
    "                    pred_counts = np.sum(validate_pred_map)\n",
    "                    sys.stdout.write('The gt counts of the above sample:{}, and the pred counts:{}\\n'.format(gt_counts, pred_counts))                        \n",
    "                \n",
    "                loss_.append(eval_loss)\n",
    "                MAE_.append(batch_ae)\n",
    "                MSE_.append(batch_se)\n",
    "                counter += 1\n",
    "            \n",
    "            # calculate the validate loss, validate MAE and validate RMSE\n",
    "            loss_ = np.reshape(loss_, [-1])\n",
    "            MAE_ = np.reshape(MAE_, [-1])\n",
    "            MSE_ = np.reshape(MSE_, [-1])\n",
    "            \n",
    "            validate_loss = np.mean(loss_)\n",
    "            validate_MAE = np.mean(MAE_)\n",
    "            validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "            \n",
    "            sys.stdout.write('In step {}, epoch {}, with loss {}, MAE = {}, MSE = {}\\n'.format(step, epoch_index + 1, validate_loss, validate_MAE, validate_RMSE))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # save model\n",
    "            if MAE > validate_MAE:\n",
    "                MAE = validate_MAE\n",
    "                torch.save(net, \"/home/zzn/PycharmProjects/SANet_pytoch/checkpoints/model_mae_b.pkl\")\n",
    "                \n",
    "            # save model\n",
    "            if MSE > validate_RMSE:\n",
    "                MSE = validate_RMSE\n",
    "                torch.save(net, \"/home/zzn/PycharmProjects/SANet_pytoch/checkpoints/model_mse_b.pkl\")\n",
    "            \n",
    "            torch.save(net, \"/home/zzn/PycharmProjects/SANet_pytoch/checkpoints/model_in_time.pkl\")\n",
    "            \n",
    "            # return train model\n",
    "            net.train()\n",
    "            dataset = dataset.train_model()\n",
    "            \n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        # B\n",
    "        x = train_img.view(-1, 3, 384, 512).cuda()\n",
    "        y = train_gt.view(-1, 1, 384, 512).cuda()\n",
    "        \n",
    "        # A\n",
    "#       x = train_img.cuda()\n",
    "#       y = train_gt.cuda()\n",
    "#       figure, (input_picture, gt_picture) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "#       input_picture.imshow(train_img[0].view(3, 384, 512).permute(1, 2, 0).numpy())\n",
    "#       input_picture.set_title(\"origin\")\n",
    "#       gt_picture.imshow(train_gt[0].view(384, 512).numpy(), cmap=plt.cm.jet)\n",
    "#       gt_picture.set_title(\"gt\")\n",
    "#       plt.show()\n",
    "        prediction = net(x)\n",
    "        loss = criterion(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
